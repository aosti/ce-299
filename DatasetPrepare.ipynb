{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86fda17d-486b-49e8-b03c-4f6bc0fe52b3",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555638c1-b220-4163-a1b2-3504ddf749e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install swifter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1559062d-2fe5-4ea8-9e7e-f2f1af434ddf",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c367a5f0-dc0c-44e2-8088-7107d013c675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineId</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Pid</th>\n",
       "      <th>Level</th>\n",
       "      <th>Component</th>\n",
       "      <th>Content</th>\n",
       "      <th>EventId</th>\n",
       "      <th>EventTemplate</th>\n",
       "      <th>ParameterList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>81109</td>\n",
       "      <td>203518</td>\n",
       "      <td>143</td>\n",
       "      <td>INFO</td>\n",
       "      <td>dfs.DataNode$DataXceiver</td>\n",
       "      <td>Receiving block blk_-1608999687919862906 src: ...</td>\n",
       "      <td>09a53393</td>\n",
       "      <td>Receiving block &lt;*&gt; src: &lt;*&gt; dest: &lt;*&gt;</td>\n",
       "      <td>['blk_-1608999687919862906', '/10.250.19.102:5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>81109</td>\n",
       "      <td>203518</td>\n",
       "      <td>35</td>\n",
       "      <td>INFO</td>\n",
       "      <td>dfs.FSNamesystem</td>\n",
       "      <td>BLOCK* NameSystem.allocateBlock: /mnt/hadoop/m...</td>\n",
       "      <td>3d91fa85</td>\n",
       "      <td>BLOCK* NameSystem.allocateBlock: &lt;*&gt; &lt;*&gt;</td>\n",
       "      <td>['/mnt/hadoop/mapred/system/job_200811092030_0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>81109</td>\n",
       "      <td>203519</td>\n",
       "      <td>143</td>\n",
       "      <td>INFO</td>\n",
       "      <td>dfs.DataNode$DataXceiver</td>\n",
       "      <td>Receiving block blk_-1608999687919862906 src: ...</td>\n",
       "      <td>09a53393</td>\n",
       "      <td>Receiving block &lt;*&gt; src: &lt;*&gt; dest: &lt;*&gt;</td>\n",
       "      <td>['blk_-1608999687919862906', '/10.250.10.6:405...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>81109</td>\n",
       "      <td>203519</td>\n",
       "      <td>145</td>\n",
       "      <td>INFO</td>\n",
       "      <td>dfs.DataNode$DataXceiver</td>\n",
       "      <td>Receiving block blk_-1608999687919862906 src: ...</td>\n",
       "      <td>09a53393</td>\n",
       "      <td>Receiving block &lt;*&gt; src: &lt;*&gt; dest: &lt;*&gt;</td>\n",
       "      <td>['blk_-1608999687919862906', '/10.250.14.224:4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81109</td>\n",
       "      <td>203519</td>\n",
       "      <td>145</td>\n",
       "      <td>INFO</td>\n",
       "      <td>dfs.DataNode$PacketResponder</td>\n",
       "      <td>PacketResponder 1 for block blk_-1608999687919...</td>\n",
       "      <td>d38aa58d</td>\n",
       "      <td>PacketResponder &lt;*&gt; for block &lt;*&gt; &lt;*&gt;</td>\n",
       "      <td>['1', 'blk_-1608999687919862906 terminating']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LineId   Date    Time  Pid Level                     Component  \\\n",
       "0       1  81109  203518  143  INFO      dfs.DataNode$DataXceiver   \n",
       "1       2  81109  203518   35  INFO              dfs.FSNamesystem   \n",
       "2       3  81109  203519  143  INFO      dfs.DataNode$DataXceiver   \n",
       "3       4  81109  203519  145  INFO      dfs.DataNode$DataXceiver   \n",
       "4       5  81109  203519  145  INFO  dfs.DataNode$PacketResponder   \n",
       "\n",
       "                                             Content   EventId  \\\n",
       "0  Receiving block blk_-1608999687919862906 src: ...  09a53393   \n",
       "1  BLOCK* NameSystem.allocateBlock: /mnt/hadoop/m...  3d91fa85   \n",
       "2  Receiving block blk_-1608999687919862906 src: ...  09a53393   \n",
       "3  Receiving block blk_-1608999687919862906 src: ...  09a53393   \n",
       "4  PacketResponder 1 for block blk_-1608999687919...  d38aa58d   \n",
       "\n",
       "                              EventTemplate  \\\n",
       "0    Receiving block <*> src: <*> dest: <*>   \n",
       "1  BLOCK* NameSystem.allocateBlock: <*> <*>   \n",
       "2    Receiving block <*> src: <*> dest: <*>   \n",
       "3    Receiving block <*> src: <*> dest: <*>   \n",
       "4     PacketResponder <*> for block <*> <*>   \n",
       "\n",
       "                                       ParameterList  \n",
       "0  ['blk_-1608999687919862906', '/10.250.19.102:5...  \n",
       "1  ['/mnt/hadoop/mapred/system/job_200811092030_0...  \n",
       "2  ['blk_-1608999687919862906', '/10.250.10.6:405...  \n",
       "3  ['blk_-1608999687919862906', '/10.250.14.224:4...  \n",
       "4      ['1', 'blk_-1608999687919862906 terminating']  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "import pandas as pd\n",
    "folder = 'dataset/HDFS_4level_0.5st'\n",
    "df = pd.read_csv('{}/HDFS.log_structured.csv'.format(folder))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f652b4-cde3-42aa-9a7e-c859c86442e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e717a85989843c381c568631d4283cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/11175629 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adding block id to dataframe\n",
    "import re\n",
    "import swifter\n",
    "\n",
    "def getBlockId(x):\n",
    "    block_id = re.findall(\"blk_.\\d+\", x)\n",
    "    if len(block_id) == 0:\n",
    "        return ''\n",
    "    else:\n",
    "        return block_id[0]\n",
    "    \n",
    "\n",
    "df['block_id'] = df['ParameterList'].swifter.apply(getBlockId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8644ae56-21d2-40ac-9cb1-b5a6fd86f238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11175629, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shape\n",
    "# Initialy, there are only 11k lines. Same number as reported in the paper \"Detecting Large-Scale System Problems by Mining Console Logs\"\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accb8aac-4cb2-412e-89b8-7a9e22728c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Differently from what is reported in the \"Drain: An Online Log Parsing Approach with Fixed Depth Tree\", \"Detecting Large-Scale System Problems by Mining Console Logs\" and \"Tools and Benchmarks for Automated Log Parsing\". \n",
    "# The number of templates found by the drain execution was close to 50, when the expected number was 29.\n",
    "# Models worked despite the difference.\n",
    "len(df['EventId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c04c437-55cc-4024-96d0-8c14ebe47c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_BlockId</th>\n",
       "      <th>cat_EventTemplate</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170659</th>\n",
       "      <td>575060</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170660</th>\n",
       "      <td>575060</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170661</th>\n",
       "      <td>575060</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170662</th>\n",
       "      <td>575060</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170663</th>\n",
       "      <td>575060</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4170664 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cat_BlockId  cat_EventTemplate  counts\n",
       "0                  0                 10       3\n",
       "1                  0                 11       1\n",
       "2                  0                 31       3\n",
       "3                  0                 33       3\n",
       "4                  0                 35       3\n",
       "...              ...                ...     ...\n",
       "4170659       575060                 12       3\n",
       "4170660       575060                 17       3\n",
       "4170661       575060                 31       3\n",
       "4170662       575060                 33       3\n",
       "4170663       575060                 35       3\n",
       "\n",
       "[4170664 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregating events by blockId.\n",
    "df['cat_BlockId'] = df['block_id'].astype('category')\n",
    "df['cat_BlockId'] = df['cat_BlockId'].cat.codes\n",
    "df['cat_EventTemplate'] = df['EventTemplate'].astype('category')\n",
    "df['cat_EventTemplate'] = df['cat_EventTemplate'].cat.codes\n",
    "result_agg = df.groupby(['cat_BlockId', 'cat_EventTemplate']).size().reset_index(name='counts')\n",
    "result_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44a436bb-4f44-4638-8db1-074a91103945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating frequency matrix. Each row corresponds to a block and each column corresponds to a message type.\n",
    "import numpy as np\n",
    "data = np.zeros((575061, 48), dtype=float)   # (rows,cols)\n",
    "for i in range(len(result_agg)):\n",
    "    data[result_agg.iloc[i]['cat_BlockId']][result_agg.iloc[i]['cat_EventTemplate']] = result_agg.iloc[i]['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a733731-f808-4b39-8c54-5a515ee6dae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlockId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blk_-1608999687919862906</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blk_7503483334202473044</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blk_-3544583377289625738</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blk_-9073992586687739851</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blk_7854771516489510256</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    BlockId    Label\n",
       "0  blk_-1608999687919862906   Normal\n",
       "1   blk_7503483334202473044   Normal\n",
       "2  blk_-3544583377289625738  Anomaly\n",
       "3  blk_-9073992586687739851   Normal\n",
       "4   blk_7854771516489510256   Normal"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading labels for blocks\n",
    "import pandas as pd\n",
    "anomaly_db = pd.read_csv('{}/anomaly_label.csv'.format(folder))\n",
    "anomaly_db.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "002899ca-849f-4559-8a79-4c69e0deb01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlockId</th>\n",
       "      <th>cat_BlockId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blk_-1000002529962039464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blk_-100000266894974466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blk_-1000007292892887521</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blk_-1000014584150379967</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blk_-1000028658773048709</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    BlockId  cat_BlockId\n",
       "0  blk_-1000002529962039464            0\n",
       "1   blk_-100000266894974466            1\n",
       "2  blk_-1000007292892887521            2\n",
       "3  blk_-1000014584150379967            3\n",
       "4  blk_-1000028658773048709            4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating maps between block ids and rows\n",
    "block_mapping = df.groupby(['block_id','cat_BlockId']).size().reset_index()\n",
    "block_mapping = block_mapping[['block_id','cat_BlockId']]\n",
    "block_mapping = block_mapping.rename(columns={'block_id':'BlockId'})\n",
    "block_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d9badef-611e-41ae-94ed-ef51cada5b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Y for each line of matrix X\n",
    "anomaly_fixed = pd.merge(anomaly_db, block_mapping, on=\"BlockId\")\n",
    "anomaly_fixed[\"cat_label\"] = anomaly_fixed[\"Label\"].astype(\"category\").cat.codes\n",
    "anomaly_fixed['cat_label'] = 1 - anomaly_fixed['cat_label']\n",
    "anomaly_fixed = anomaly_fixed.sort_values(by=['cat_BlockId']).reset_index()\n",
    "Y = anomaly_fixed['cat_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3393fe1e-dfc6-4b75-90a7-6dd31f3e2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting unique lines from the data matrix\n",
    "X, x_index = np.unique(data, axis=0, return_index=True)\n",
    "Y = Y[x_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73a64246-89d8-4ddb-b262-a45ebc4dcff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset has 597 samples, 393 of them are anomalous\n"
     ]
    }
   ],
   "source": [
    "print(\"Final dataset has {} samples, {} of them are anomalous\".format(X.shape[0], sum(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "807971a4-bfb5-4de8-ab9e-e138e530fc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting and saving dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "np.savez('{}/splited_dataset'.format(folder), x_train=X_train, y_train=y_train, x_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a1cc8-a20d-4cbc-b9b3-e543064a3816",
   "metadata": {},
   "source": [
    "# Generated dataset for federated agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "930bc039-ce72-4f19-b379-45921af65122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: test set and train set contain different labels\n",
      "Party_ 0\n",
      "nb_x_train:  (150, 48) nb_x_test:  (66, 48)\n",
      "* Label  0  samples:  48\n",
      "* Label  1  samples:  102\n",
      "Finished! :) Data saved in  dataset/HDFS_4level_0.5st\n",
      "Party_ 1\n",
      "nb_x_train:  (150, 48) nb_x_test:  (66, 48)\n",
      "* Label  0  samples:  53\n",
      "* Label  1  samples:  97\n",
      "Finished! :) Data saved in  dataset/HDFS_4level_0.5st\n",
      "Party_ 2\n",
      "nb_x_train:  (150, 48) nb_x_test:  (66, 48)\n",
      "* Label  0  samples:  60\n",
      "* Label  1  samples:  90\n",
      "Finished! :) Data saved in  dataset/HDFS_4level_0.5st\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset for the parties\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "folder = 'dataset/HDFS_4level_0.5st'\n",
    "data = np.load('{}/splited_dataset.npz'.format(folder))\n",
    "\n",
    "def generate_parties_dataset(nb_dp_per_party, should_stratify, party_folder, data):\n",
    "    x_train, y_train,x_test, y_test = data['x_train'], data['y_train'], data['x_test'], data['y_test']\n",
    "    labels, train_counts = np.unique(y_train, return_counts=True)\n",
    "    te_labels, test_counts = np.unique(y_test, return_counts=True)\n",
    "    if np.all(np.isin(labels, te_labels)):\n",
    "        print(\"Warning: test set and train set contain different labels\")\n",
    "\n",
    "    num_train = np.shape(y_train)[0]\n",
    "    num_test = np.shape(y_test)[0]\n",
    "    num_labels = np.shape(np.unique(y_test))[0]\n",
    "    nb_parties = len(nb_dp_per_party)\n",
    "\n",
    "    if should_stratify:\n",
    "        # Sample according to source label distribution\n",
    "        train_probs = {\n",
    "            label: train_counts[label] / float(num_train) for label in labels}\n",
    "        test_probs = {label: test_counts[label] /\n",
    "                      float(num_test) for label in te_labels}\n",
    "    else:\n",
    "        # Sample uniformly\n",
    "        train_probs = {label: 1.0 / len(labels) for label in labels}\n",
    "        test_probs = {label: 1.0 / len(te_labels) for label in te_labels}\n",
    "\n",
    "    for idx, dp in enumerate(nb_dp_per_party):\n",
    "        train_p = np.array([train_probs[y_train[idx]]\n",
    "                            for idx in range(num_train)])\n",
    "        train_p /= np.sum(train_p)\n",
    "        train_indices = np.random.choice(num_train, dp, p=train_p)\n",
    "        test_p = np.array([test_probs[y_test[idx]] for idx in range(num_test)])\n",
    "        test_p /= np.sum(test_p)\n",
    "\n",
    "        # Split test evenly\n",
    "        test_indices = np.random.choice(\n",
    "            num_test, int(num_test / nb_parties), p=test_p)\n",
    "\n",
    "        \n",
    "        sc = StandardScaler()\n",
    "        x_train_pi = x_train[train_indices]\n",
    "        x_train_pi = sc.fit_transform(x_train_pi)\n",
    "        y_train_pi = y_train[train_indices]\n",
    "        \n",
    "        x_test_pi = x_test[test_indices]\n",
    "        x_test_pi = sc.transform(x_test_pi)\n",
    "        y_test_pi = y_test[test_indices]\n",
    "\n",
    "        # Now put it all in an npz\n",
    "        name_file = 'data_party' + str(idx) + '.npz'\n",
    "        name_file = os.path.join(party_folder, name_file)\n",
    "        np.savez(name_file, x_train=x_train_pi, y_train=y_train_pi,\n",
    "                 x_test=x_test_pi, y_test=y_test_pi)\n",
    "\n",
    "        print_statistics(idx, x_test_pi, x_train_pi, num_labels, y_train_pi)\n",
    "\n",
    "        print('Finished! :) Data saved in ', party_folder)\n",
    "        \n",
    "def print_statistics(i, x_test_pi, x_train_pi, nb_labels, y_train_pi):\n",
    "    print('Party_', i)\n",
    "    print('nb_x_train: ', np.shape(x_train_pi),\n",
    "          'nb_x_test: ', np.shape(x_test_pi))\n",
    "    for l in range(nb_labels):\n",
    "        print('* Label ', l, ' samples: ', (y_train_pi == l).sum())\n",
    "\n",
    "\n",
    "# Same distribution for all participants        \n",
    "generate_parties_dataset([150 for _ in range(3)], False, folder, data)\n",
    "# Participants with 10%, 25% and 65% of the dataset.\n",
    "# generate_parties_dataset([int(450 * 0.10), int(450 * 0.25), int(450 * 0.65)], False, folder, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6145ff-e81a-4697-96e4-8399a0aa7210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
